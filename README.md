# ğŸŒ‰ OmniBridge - AI Image Captioning

AI-powered image captioning using BLIP-2 vision-language model.

## ğŸš€ Live Demo

**Try it now:** [https://huggingface.co/spaces/madhavan02/OmniBridge](https://huggingface.co/spaces/madhavan02/OmniBridge)

## Features

- ğŸ“· Upload any image
- ğŸ§  State-of-the-art BLIP-2 model (Salesforce/blip2-opt-2.7b)
- âš¡ Trained on 400M+ image-text pairs
- ğŸ¯ Accurate, natural language captions

## Tech Stack

- **Model:** Salesforce BLIP-2 (OPT-2.7B)
- **Frontend:** Gradio
- **Hosting:** HuggingFace Spaces
- **Training Infrastructure:** Indiana University Big Red 200 (NVIDIA A100)

## Project Structure

```
OmniBridge/
â”œâ”€â”€ huggingface_space/     # HuggingFace Spaces deployment
â”‚   â”œâ”€â”€ app.py             # Gradio application
â”‚   â”œâ”€â”€ requirements.txt   # Dependencies
â”‚   â””â”€â”€ README.md          # Space configuration
â”œâ”€â”€ frontend/              # Local demo UI
â”œâ”€â”€ inference.py           # Custom inference code
â””â”€â”€ phase1_train.py        # Q-Former training script
```

## Author

**Madhavan Balaji**

---

â­ Star this repo if you found it helpful!
